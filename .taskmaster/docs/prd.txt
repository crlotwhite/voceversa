# **프로젝트 VoceVersa: 차세대 하이브리드 가창 합성 엔진**

## **제품 요구사항 문서 (PRD) 및 상세 기술 설계**

### **1\. 제품 요구사항 문서 (PRD)**

#### **1.1. 개요 (Overview)**

**VoceVersa**는 **유닛 선택 합성(예: PSOLA)**, 통계 기반 방식(Statistical Parametric Synthesis), 그리고 딥러닝 기반 방식을 모두 지원하는 차세대 하이브리드 음성/가창 합성 엔진입니다. 기존의 단일 방식에 종속된 엔진들과 달리, 사용자와 개발자는 필요에 따라 다양한 합성 알고리즘(예: PSOLA, WORLD, llsm2, DiffSinger)을 블록처럼 조립, 교체, 혼용하여 원하는 음색과 품질을 얻을 수 있습니다. 본 프로젝트의 핵심은 **모듈성, 확장성, 그리고 플랫폼 독립성**입니다.

#### **1.2. 목표 (Goals)**

* **하이브리드 합성 지원**: 단일 엔진 내에서 **유닛 선택 방식**, 통계 기반 신호 처리 모델, 딥러닝 모델을 동등하게 지원하고 상호 운용성을 보장합니다.
* **그래프 기반 모듈화**: 모든 신호 처리 및 합성 단계를 '노드(Node)'로 추상화하여, 계산 그래프(Computation Graph) 형태로 자유롭게 파이프라인을 구성할 수 있도록 설계합니다.
* **크로스플랫폼 호환성**: Windows, macOS, Ubuntu, Android, iOS 등 주요 플랫폼에서 동일한 코어 로직이 동작하도록 구현합니다.
* **레거시 및 최신 프런트엔드 지원**: UTAU와 같은 기존 프런트엔드와의 호환성을 유지하는 동시에, 현대적인 애플리케이션에 쉽게 통합될 수 있는 범용 인터페이스를 제공합니다.

#### **1.3. 사용자 프로필 및 사용 사례 (User Profiles & Use Cases)**

* **음악 프로듀서/아마추어 창작자**: UTAU 프런트엔드에서 VoceVersa 엔진을 사용하여 기존 워크플로우를 유지하면서도, **PSOLA 기반의 자연스러운 음색**, WORLD 기반의 깨끗한 사운드나 DiffSinger 기반의 표현력 높은 사운드를 선택적으로 활용합니다.
* **애플리케이션 개발자**: 모바일 노래방 앱, 보이스챗 아바타, AI 비서 등에 VoceVersa 엔진 라이브러리를 통합하여 실시간 또는 오프라인 음성 합성을 구현합니다.
* **음성 합성 연구자**: 새로운 합성 알고리즘을 개발 시, 전체 엔진을 새로 만들 필요 없이 커스텀 '노드'만 구현하여 기존의 F0 추출, 보코더 등과 쉽게 결합하고 성능을 테스트합니다.

#### **1.4. 요구사항 (Requirements)**

##### **기능 요구사항 (Functional Requirements)**

* **FR1: 합성 모델 재구현**
  * **(신규) PSOLA 기반 유닛 선택 합성 알고리즘을 내장해야 합니다. (음소 단위 DB 관리, 최적 유닛 선택, 파형 중첩/추가 포함)**
  * WORLD 보코더(F0 추출, 스펙트럼, 비주기성 지표 분석/합성) 알고리즘을 내장해야 합니다.
  * llsm/llsm2의 통계 기반 파라미터 생성 알고리즘을 내장해야 합니다.
  * DiffSinger의 어쿠스틱 모델 및 보코더 개념을 지원하는 딥러닝 추론 파이프라인을 구축할 수 있어야 합니다.
* **FR2: 계산 그래프 실행**
  * 사용자는 정의된 '노드'들을 연결하여 커스텀 합성 파이프라인(계산 그래프)을 생성할 수 있어야 합니다.
  * 예: \[입력\] \-\> \[유닛선택 노드\] \-\> \[PSOLA 합성 노드\] \-\> \[출력\]
* **FR3: UTAU 인터페이스 제공**
  * world4utau의 동작 방식을 분석하여, UTAU가 생성하는 파일(임시 \*.wav, \*.frq 등)과 파라미터를 입력받아 처리하는 어댑터를 구현해야 합니다.
  * UTAU 플러그인(resampler.exe 또는 wavtool.exe 규격)에 맞는 실행 파일을 생성할 수 있어야 합니다.
* **FR4: 범용 입력 인터페이스 제공**
  * UTAU 외의 프런트엔드 연동을 위해 노트, 가사, 발음 기호, 피치 커브, 컨트롤 파라미터 등을 구조화된 데이터로 입력받는 C-ABI 호환 공개 API를 명세하고 제공해야 합니다.
* **FR5: 라이선스 및 특허**
  * 참고 레포지토리의 코드를 직접 링크하지 않고, 공개된 논문과 알고리즘 설명을 기반으로 재구현합니다.
  * 재구현하는 모든 알고리즘에 대해 라이선스 및 특허 문제를 사전에 검토하고 기록해야 합니다.

##### **비기능 요구사항 (Non-Functional Requirements)**

* **NFR1: 성능**: 실시간 합성이 요구되는 경우(예: 모바일 앱)를 대비해 저지연성을 고려하여 설계하되, 오프라인 고품질 배치(batch) 처리도 효율적으로 수행할 수 있어야 합니다.
* **NFR2: 이식성**: 플랫폼 종속적인 코드(파일 I/O, 스레딩)를 인터페이스 뒤로 완전히 분리하여 코어 로직의 이식성을 극대화해야 합니다.
* **NFR3: 확장성**: 새로운 신호 처리 기법이나 딥러닝 모델을 추가할 때, 기존 코드를 수정하지 않고 새로운 '노드' 클래스를 구현하여 그래프에 통합할 수 있는 구조여야 합니다.

### **2\. 상세 기술 설계**

#### **2.1. 언어 선택: C++**

(변경 없음)

#### **2.2. 컴포넌트 설계 (Component Design)**

(기존 구조 유지, 노드 구현체 예시 추가)

* **EngineCore (엔진 코어)**
* **IPlatformIO (플랫폼 I/O 인터페이스)**
* **ISynthesisNode (합성 노드 인터페이스)**
* **DataPacket (데이터 패킷)**
* **ComputationGraph (계산 그래프)**
* **노드 구현체 예시**
  * **(신규) UnitSelectionNode**: 목표 발음, 피치, 길이에 가장 적합한 파형 조각(diphone 등)을 사전 구축된 음성 DB에서 선택합니다.
  * **(신규) PsolaSynthesisNode**: UnitSelectionNode에서 선택된 파형 조각들을 입력받아, 목표 피치와 길이에 맞춰 PSOLA 알고리즘으로 파형을 조작하고 부드럽게 연결하여 최종 음성을 생성합니다.
  * **WorldAnalysisNode**: 입력 \*.wav를 받아 F0, 스펙트로그램, 비주기성 지표를 DataPacket에 담아 출력합니다.
  * **LlsmModelNode**: UTAU 파라미터와 음원 정보를 받아 llsm2 알고리즘으로 스펙트럼 파라미터를 생성합니다.
  * **OnnxInferenceNode**: ONNX Runtime을 래핑(wrapping)합니다. \*.onnx 모델 파일 경로와 입력 텐서를 받아 추론을 수행하고 결과 텐서를 출력합니다.
  * **WorldSynthesisNode**: F0와 합성된 스펙트로그램을 받아 최종 \*.wav 파형을 생성합니다.
* 어댑터 및 외부 인터페이스
  (변경 없음)

#### **2.3. 의존성 (Dependencies)**

(변경 없음)

#### **2.4. CI/CD 및 마일스톤 (CI/CD & Milestones)**

* CI (Continuous Integration): GitHub Actions 활용
  (변경 없음)
* **마일스톤 (Milestones)**
  * **M1: 코어 아키텍처 및 WORLD 구현 (3개월)**
    * **목표**: 기본 구조 확립 및 신호처리 기반 합성 파이프라인 검증.
    * **주요 과업**:
      * CMake 프로젝트 구조 설정, GitHub Actions CI 구축.
      * ISynthesisNode, ComputationGraph, DataPacket 등 핵심 인터페이스 및 클래스 정의.
      * WORLD 알고리즘(분석/합성)을 C++ 노드로 재구현.
      * WAV 파일 입/출력이 가능한 간단한 커맨드라인 테스트 프로그램 제작.
  * **M2: 클래식 합성 방식 및 UTAU 어댑터 구현 (4개월)**
    * **목표**: 기존 UTAU 생태계 호환성 및 전통적 합성 방식 지원.
    * **주요 과업**:
      * UtauAdapter 구현 및 UTAU 입력 파라미터 분석.
      * llsm2 알고리즘을 LlsmModelNode로 재구현.
      * **(신규) UnitSelectionNode 및 PsolaSynthesisNode 구현.**
      * WORLD, PSOLA 등 다양한 백엔드를 선택할 수 있는 resampler 버전 완성.
      * **법무팀/전문가를 통한 재구현 알고리즘 라이선스 및 특허 분석 완료.**
  * **M3: 딥러닝 지원 및 범용 API 설계 (3개월)**
    * **목표**: 딥러닝 모델 통합 및 외부 확장성 제공.
    * **주요 과업**:
      * ONNX Runtime 라이브러리 연동.
      * OnnxInferenceNode 구현 및 테스트.
      * 사전 학습된 DiffSinger ONNX 모델을 이용한 합성 파이프라인(계산 그래프) 구축 PoC.
      * PublicCApi.h의 명세 확정 및 구현.
  * **M4: 플랫폼 이식 및 안정화 (2개월)**
    * **목표**: 모바일 플랫폼 지원 및 API 완성.
    * **주요 과업**:
      * Android(JNI) 및 iOS(Objective-C++ Wrapper)용 빌드 스크립트 및 예제 프로젝트 작성.
      * IPlatformIO의 모바일 플랫폼별 구현체 작성.
      * 전체 기능에 대한 통합 테스트 및 버그 수정.
      * 공식 API 문서 작성.
  * **M5: v1.0 릴리스**
    * 베타 테스트를 통해 수집된 피드백 반영.
    * 최종 패키징 및 공식 릴리스.